{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (60, 36, 60)\n",
      "Data type: int64\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"model/sketch.nyu/results_sketch/1194.npy\")\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Data type: {data.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (60, 36, 60)\n",
      "Value at (10, 20, 30): 0\n",
      "Label distribution: {0: 49793, 1: 3930, 2: 3522, 3: 19470, 4: 220, 5: 641, 6: 8580, 7: 14, 8: 4366, 9: 26, 10: 24487, 11: 14551}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your semantic labeling data\n",
    "data = np.load('model/sketch.nyu/results/1004.npy')\n",
    "# data = np.load('model/sketch.nyu/results/1004.npy')\n",
    "\n",
    "print(\"Data shape: \", data.shape)\n",
    "\n",
    "x, y, z = 10, 20, 30  # Example coordinates\n",
    "value = data[x, y, z]\n",
    "print(f\"Value at ({x}, {y}, {z}): {value}\")\n",
    "\n",
    "# Print a label distribution\n",
    "unique, counts = np.unique(data, return_counts=True)\n",
    "label_counts = dict(zip(unique, counts))\n",
    "print(\"Label distribution:\", label_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([0.12156863, 0.46666667, 0.70588235]), 1: array([0.68235294, 0.78039216, 0.90980392]), 2: array([1.        , 0.73333333, 0.47058824]), 3: array([0.59607843, 0.8745098 , 0.54117647]), 4: array([1.        , 0.59607843, 0.58823529]), 5: array([0.77254902, 0.69019608, 0.83529412]), 6: array([0.54901961, 0.3372549 , 0.29411765]), 7: array([0.89019608, 0.46666667, 0.76078431]), 8: array([0.49803922, 0.49803922, 0.49803922]), 9: array([0.7372549 , 0.74117647, 0.13333333]), 10: array([0.09019608, 0.74509804, 0.81176471]), 11: array([0.61960784, 0.85490196, 0.89803922])}\n"
     ]
    }
   ],
   "source": [
    "# Single File Visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "\n",
    "# Load your semantic labeling data\n",
    "data = np.load('model/sketch.nyu/results/1194.npy')\n",
    "\n",
    "# Generate a colormap with 12 distinct colors\n",
    "cmap = plt.get_cmap(\"tab20\")  # 'tab20' has 20 distinct colors\n",
    "colors = cmap(np.linspace(0, 1, 12))  # Generate 12 colors\n",
    "\n",
    "# Create a mapping from labels to colors (in RGB format expected by Open3D)\n",
    "label_to_color = {label: colors[label][:3] for label in range(12)}\n",
    "# print(label_to_color)\n",
    "\n",
    "# Create a point cloud where each point represents a voxel's center, colored by its semantic label\n",
    "points = []\n",
    "colors = []\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[1]):\n",
    "        for k in range(data.shape[2]):\n",
    "            label = data[i, j, k]\n",
    "            if label in label_to_color:  # Check if the label has a defined color\n",
    "                # Add the voxel center point (adjust the scaling as needed)\n",
    "                points.append([i, j, k])\n",
    "                # Add the color corresponding to the label\n",
    "                colors.append(label_to_color[label])\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "points = np.array(points)\n",
    "colors = np.array(colors)\n",
    "\n",
    "# Create and visualize the colored point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use to view the model keys in the pre-trained model ###\n",
    "\n",
    "import torch\n",
    "\n",
    "# Path to your .pth file\n",
    "file_path = 'DATA/pytorch-weight/resnet50-imagenet.pth'\n",
    "\n",
    "# Load the file\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "# Assuming the file contains a state dictionary, print its keys\n",
    "if isinstance(state_dict, dict):\n",
    "    for key in state_dict.keys():\n",
    "        print(key)\n",
    "else:\n",
    "    print(\"Loaded object is not a dictionary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 19, 3)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.nccl.version())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HHA and TSDF Conversion Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL OF THE FOLLOWING CODE IS FROM: https://github.com/charlesCXK/Depth2HHA-python/tree/master\n",
    "\n",
    "# --*-- coding:utf-8 --*--\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import signal\n",
    "\n",
    "'''\n",
    "helper function\n",
    "'''\n",
    "def filterItChopOff(f, r, sp):\n",
    "    f[np.isnan(f)] = 0\n",
    "    H, W, d = f.shape\n",
    "    B = np.ones([2 * r + 1, 2 * r + 1])     # 2r+1 * 2r+1 neighbourhood\n",
    "\n",
    "    minSP = cv2.erode(sp, B, iterations=1)\n",
    "    maxSP = cv2.dilate(sp, B, iterations=1)\n",
    "\n",
    "    ind = np.where(np.logical_or(minSP != sp, maxSP != sp))\n",
    "\n",
    "    spInd = np.reshape(range(np.size(sp)), sp.shape,'F')\n",
    "\n",
    "    delta = np.zeros(f.shape)\n",
    "    delta = np.reshape(delta, (H * W, d), 'F')\n",
    "    f = np.reshape(f, (H * W, d),'F')\n",
    "\n",
    "    # calculate delta\n",
    "\n",
    "    I, J = np.unravel_index(ind, [H, W], 'C')\n",
    "    for i in range(np.size(ind)):\n",
    "        x = I[i]\n",
    "        y = J[i]\n",
    "        clipInd = spInd[max(0, x - r):min(H-1, x + r), max(0, y - r):min(W-1, y + r)]\n",
    "        diffInd = clipInd[sp[clipInd] != sp[x, y]]\n",
    "        delta[ind[i], :] = np.sum(f[diffInd, :], 1)\n",
    "    delta = np.reshape(delta, (H, W, d), 'F')\n",
    "    f = np.reshape(f, (H, W, d), 'F')\n",
    "    fFilt = np.zeros([H, W, d])\n",
    "\n",
    "    for i in range(f.shape[2]):\n",
    "        #  fFilt(:,:,i) = filter2(B, f(:,:,i));\n",
    "        tmp = cv2.filter2D(np.rot90(f[:, :, i], 2), -1, np.rot90(np.rot90(B, 2), 2))\n",
    "        tmp = signal.convolve2d(np.rot90(f[:, :, i], 2), np.rot90(np.rot90(B, 2), 2), mode=\"same\")\n",
    "        fFilt[:, :, i] = np.rot90(tmp, 2)\n",
    "    fFilt = fFilt - delta\n",
    "    return fFilt\n",
    "\n",
    "'''\n",
    "helper function\n",
    "'''\n",
    "def mutiplyIt(AtA_1, Atb):\n",
    "    result = np.zeros([Atb.shape[0], Atb.shape[1], 3])\n",
    "    result[:, :, 0] = np.multiply(AtA_1[:, :, 0], Atb[:, :, 0]) + np.multiply(AtA_1[:, :, 1],\n",
    "                                                                              Atb[:, :, 1]) + np.multiply(\n",
    "        AtA_1[:, :, 2], Atb[:, :, 2])\n",
    "    result[:, :, 1] = np.multiply(AtA_1[:, :, 1], Atb[:, :, 0]) + np.multiply(AtA_1[:, :, 3],\n",
    "                                                                              Atb[:, :, 1]) + np.multiply(\n",
    "        AtA_1[:, :, 4], Atb[:, :, 2])\n",
    "    result[:, :, 2] = np.multiply(AtA_1[:, :, 2], Atb[:, :, 0]) + np.multiply(AtA_1[:, :, 4],\n",
    "                                                                              Atb[:, :, 1]) + np.multiply(\n",
    "        AtA_1[:, :, 5], Atb[:, :, 2])\n",
    "    return result\n",
    "\n",
    "'''\n",
    "helper function\n",
    "'''\n",
    "def invertIt(AtA):\n",
    "    AtA_1 = np.zeros([AtA.shape[0], AtA.shape[1], 6])\n",
    "    AtA_1[:, :, 0] = np.multiply(AtA[:, :, 3], AtA[:, :, 5]) - np.multiply(AtA[:, :, 4], AtA[:, :, 4])\n",
    "    AtA_1[:, :, 1] = -np.multiply(AtA[:, :, 1], AtA[:, :, 5]) + np.multiply(AtA[:, :, 2], AtA[:, :, 4])\n",
    "    AtA_1[:, :, 2] = np.multiply(AtA[:, :, 1], AtA[:, :, 4]) - np.multiply(AtA[:, :, 2], AtA[:, :, 3])\n",
    "    AtA_1[:, :, 3] = np.multiply(AtA[:, :, 0], AtA[:, :, 5]) - np.multiply(AtA[:, :, 2], AtA[:, :, 2])\n",
    "    AtA_1[:, :, 4] = -np.multiply(AtA[:, :, 0], AtA[:, :, 4]) + np.multiply(AtA[:, :, 1], AtA[:, :, 2])\n",
    "    AtA_1[:, :, 5] = np.multiply(AtA[:, :, 0], AtA[:, :, 3]) - np.multiply(AtA[:, :, 1], AtA[:, :, 1])\n",
    "\n",
    "    x1 = np.multiply(AtA[:, :, 0], AtA_1[:, :, 0])\n",
    "    x2 = np.multiply(AtA[:, :, 1], AtA_1[:, :, 1])\n",
    "    x3 = np.multiply(AtA[:, :, 2], AtA_1[:, :, 2])\n",
    "\n",
    "    detAta = x1 + x2 + x3\n",
    "    return AtA_1, detAta\n",
    "\n",
    "'''\n",
    "Compute the direction of gravity\n",
    "N: normal field\n",
    "iter: number of 'big' iterations\n",
    "'''\n",
    "def getYDir(N, angleThresh, iter, y0):\n",
    "    y = y0\n",
    "    for i in range(len(angleThresh)):\n",
    "        thresh = np.pi * angleThresh[i] / 180   # convert it to radian measure\n",
    "        y = getYDirHelper(N, y, thresh, iter[i])\n",
    "    return y\n",
    "\n",
    "'''\n",
    "N: HxWx3 matrix with normal at each pixel.\n",
    "y0: the initial gravity direction\n",
    "thresh: in degrees the threshold for mapping to parallel to gravity and perpendicular to gravity\n",
    "iter: number of iterations to perform\n",
    "'''\n",
    "def getYDirHelper(N, y0, thresh, num_iter):\n",
    "    dim = N.shape[0] * N.shape[1]\n",
    "\n",
    "    # change the third dimension to the first-order. (480, 680, 3) => (3, 480, 680)\n",
    "    nn = np.swapaxes(np.swapaxes(N,0,2),1,2)\n",
    "    nn = np.reshape(nn, (3, dim), 'F')\n",
    "\n",
    "    # remove these whose number is NAN\n",
    "    idx = np.where(np.invert(np.isnan(nn[0,:])))[0]\n",
    "    nn = nn[:,idx]\n",
    "\n",
    "    # Set it up as a optimization problem\n",
    "    yDir = y0;\n",
    "    for i in range(num_iter):\n",
    "        sim0 = np.dot(yDir.T, nn)\n",
    "        indF = abs(sim0) > np.cos(thresh)       # calculate 'floor' set.    |sin(theta)| < sin(thresh) ==> |cos(theta)| > cos(thresh)\n",
    "        indW = abs(sim0) < np.sin(thresh)       # calculate 'wall' set.\n",
    "        if(len(indF.shape) == 2):\n",
    "            NF = nn[:, indF[0,:]]\n",
    "            NW = nn[:, indW[0,:]]\n",
    "        else:\n",
    "            NF = nn[:, indF]\n",
    "            NW = nn[:, indW]\n",
    "        A = np.dot(NW, NW.T) - np.dot(NF, NF.T)\n",
    "        b = np.zeros([3,1])\n",
    "        c = NF.shape[1]\n",
    "        w,v = np.linalg.eig(A)      # w:eigenvalues; v:eigenvectors\n",
    "        min_ind = np.argmin(w)      # min index\n",
    "        newYDir = v[:,min_ind]\n",
    "        yDir = newYDir * np.sign(np.dot(yDir.T, newYDir))\n",
    "    return yDir\n",
    "\n",
    "'''\n",
    "getRMatrix: Generate a rotation matrix that\n",
    "            if yf is a scalar, rotates about axis yi by yf degrees\n",
    "            if yf is an axis, rotates yi to yf in the direction given by yi x yf\n",
    "Input: yi is an axis 3x1 vector\n",
    "       yf could be a scalar of axis\n",
    "\n",
    "'''\n",
    "def getRMatrix(yi, yf):\n",
    "    if (np.isscalar(yf)):\n",
    "        ax = yi / np.linalg.norm(yi)        # norm(A) = max(svd(A))\n",
    "        phi = yf\n",
    "    else:\n",
    "        yi = yi / np.linalg.norm(yi)\n",
    "        yf = yf / np.linalg.norm(yf)\n",
    "        ax = np.cross(yi.T, yf.T).T\n",
    "        ax = ax / np.linalg.norm(ax)\n",
    "        # find angle of rotation\n",
    "        phi = np.degrees(np.arccos(np.dot(yi.T, yf)))\n",
    "\n",
    "    if (abs(phi) > 0.1):\n",
    "        phi = phi * (np.pi / 180)\n",
    "        ax = ax.flatten()\n",
    "\n",
    "        s_hat = np.array([[0, -ax[2], ax[1]],\n",
    "                          [ax[2], 0, -ax[0]],\n",
    "                          [-ax[1], ax[0], 0]])\n",
    "        R = np.eye(3) + np.sin(phi) * s_hat + (1 - np.cos(phi)) * np.dot(s_hat, s_hat)      # dot???\n",
    "    else:\n",
    "        R = np.eye(3)\n",
    "    return R\n",
    "\n",
    "'''\n",
    "Calibration of gravity direction \n",
    "'''\n",
    "def rotatePC(pc, R):\n",
    "    if(np.array_equal(R, np.eye(3))):\n",
    "        return pc\n",
    "    else:\n",
    "        R = R.astype(np.float64)\n",
    "        dim = pc.shape[0] * pc.shape[1]\n",
    "        pc = np.swapaxes(np.swapaxes(pc, 0, 2), 1, 2)\n",
    "        res = np.reshape(pc, (3, dim), 'F')\n",
    "        res = np.dot(R, res)\n",
    "        res = np.reshape(res, pc.shape, 'F')\n",
    "        res = np.swapaxes(np.swapaxes(res, 0, 1), 1, 2)\n",
    "        return res\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "'''\n",
    "z: depth image in 'centimetres'\n",
    "missingMask: a mask\n",
    "C: camera matrix\n",
    "'''\n",
    "def processDepthImage(z, missingMask, C):\n",
    "    yDirParam_angleThresh = np.array([45, 15]) # threshold to estimate the direction of the gravity\n",
    "    yDirParam_iter = np.array([5, 5])\n",
    "    yDirParam_y0 = np.array([0, 1, 0])\n",
    "\n",
    "    normalParam_patchSize = np.array([3, 10])\n",
    "\n",
    "    X, Y, Z = getPointCloudFromZ(z, C, 1)\n",
    "\n",
    "    # with open('pd.txt', 'w', encoding='utf-8') as f:\n",
    "    #     for i in range(X.shape[0]):\n",
    "    #         for j in range(X.shape[1]):\n",
    "    #             f.write('{} {} {}\\n'.format(str(X[i,j]), str(Y[i,j]), str(Z[i,j])))\n",
    "\n",
    "    # restore x-y-z position\n",
    "    pc = np.zeros([z.shape[0], z.shape[1], 3])\n",
    "    pc[:,:,0] = X\n",
    "    pc[:,:,1] = Y\n",
    "    pc[:,:,2] = Z\n",
    "\n",
    "    N1, b1 = computeNormalsSquareSupport(z/100, missingMask, normalParam_patchSize[0],\n",
    "    1, C, np.ones(z.shape))\n",
    "    N2, b2 = computeNormalsSquareSupport(z/100, missingMask, normalParam_patchSize[1],\n",
    "    1, C, np.ones(z.shape))\n",
    "\n",
    "    N = N1\n",
    "\n",
    "    # Compute the direction of gravity\n",
    "    yDir = getYDir(N2, yDirParam_angleThresh, yDirParam_iter, yDirParam_y0)\n",
    "    y0 = np.array([[0, 1, 0]]).T\n",
    "    R = getRMatrix(y0, yDir)\n",
    "\n",
    "    # rotate the pc and N\n",
    "    NRot = rotatePC(N, R.T)\n",
    "\n",
    "    pcRot = rotatePC(pc, R.T)\n",
    "    h = -pcRot[:,:,1]\n",
    "    yMin = np.percentile(h, 0)\n",
    "    if (yMin > -90):\n",
    "        yMin = -130\n",
    "    h = h - yMin\n",
    "\n",
    "    return pc, N, yDir, h,  pcRot, NRot\n",
    "\n",
    "'''\n",
    "getPointCloudFromZ: use depth image and camera matrix to get pointcloud\n",
    "Z is in 'centimetres'\n",
    "C: camera matrix\n",
    "s: is the factor by which Z has been upsampled\n",
    "'''\n",
    "def getPointCloudFromZ(Z, C, s=1):\n",
    "    Z = Z.mean(axis=2)\n",
    "    h, w = Z.shape\n",
    "    xx, yy = np.meshgrid(np.array(range(w))+1, np.array(range(h))+1)\n",
    "    # color camera parameters\n",
    "    cc_rgb = C[0:2,2] * s       # the first two lines of colomn-3, x0 and the y0\n",
    "    fc_rgb = np.diag(C[0:2,0:2]) * s    # number on the diagonal line\n",
    "    x3 = np.multiply((xx - cc_rgb[0]), Z) / fc_rgb[0]\n",
    "    y3 = np.multiply((yy - cc_rgb[1]), Z) / fc_rgb[1]\n",
    "    z3 = Z\n",
    "    return x3, y3, z3\n",
    "\n",
    "'''\n",
    "  Clip out a 2R+1 x 2R+1 window at each point and estimate \n",
    "  the normal from points within this window. In case the window \n",
    "  straddles more than a single superpixel, only take points in the \n",
    "  same superpixel as the centre pixel. \n",
    "  \n",
    "Input:\n",
    "    depthImage: in meters\n",
    "    missingMask:  boolean mask of what data was missing\n",
    "    R: radius of clipping\n",
    "    sc: to upsample or not\n",
    "    superpixels:  superpixel map to define bounadaries that should\n",
    "                    not be straddled\n",
    "'''\n",
    "def computeNormalsSquareSupport(depthImage, missingMask, R, sc, cameraMatrix, superpixels):\n",
    "    depthImage = depthImage*100     # convert to centi metres\n",
    "    X, Y, Z = getPointCloudFromZ(depthImage, cameraMatrix, sc)\n",
    "    Xf = X\n",
    "    Yf = Y\n",
    "    Zf = Z\n",
    "    pc = np.zeros([depthImage.shape[0], depthImage.shape[1], 3])\n",
    "    pc[:,:,0] = Xf\n",
    "    pc[:,:,1] = Yf\n",
    "    pc[:,:,2] = Zf\n",
    "    XYZf = np.copy(pc)\n",
    "\n",
    "    # find missing value\n",
    "    ind = np.where(missingMask == 1)\n",
    "    X[ind] = np.nan\n",
    "    Y[ind] = np.nan\n",
    "    Z[ind] = np.nan\n",
    "\n",
    "    one_Z = np.expand_dims(1 / Z, axis=2)\n",
    "    X_Z = np.divide(X, Z)\n",
    "    Y_Z = np.divide(Y, Z)\n",
    "    one = np.copy(Z)\n",
    "    one[np.invert(np.isnan(one[:, :]))] = 1\n",
    "    ZZ = np.multiply(Z, Z)\n",
    "    X_ZZ = np.expand_dims(np.divide(X, ZZ), axis=2)\n",
    "    Y_ZZ = np.expand_dims(np.divide(Y, ZZ), axis=2)\n",
    "\n",
    "    X_Z_2 = np.expand_dims(np.multiply(X_Z, X_Z), axis=2)\n",
    "    XY_Z = np.expand_dims(np.multiply(X_Z, Y_Z), axis=2)\n",
    "    Y_Z_2 = np.expand_dims(np.multiply(Y_Z, Y_Z), axis=2)\n",
    "\n",
    "    AtARaw = np.concatenate((X_Z_2, XY_Z, np.expand_dims(X_Z, axis=2), Y_Z_2,\n",
    "                             np.expand_dims(Y_Z, axis=2), np.expand_dims(one, axis=2)), axis=2)\n",
    "\n",
    "    AtbRaw = np.concatenate((X_ZZ, Y_ZZ, one_Z), axis=2)\n",
    "\n",
    "    # with clipping\n",
    "    AtA = filterItChopOff(np.concatenate((AtARaw, AtbRaw), axis=2), R, superpixels)\n",
    "    Atb = AtA[:, :, AtARaw.shape[2]:]\n",
    "    AtA = AtA[:, :, :AtARaw.shape[2]]\n",
    "\n",
    "    AtA_1, detAtA = invertIt(AtA)\n",
    "    N = mutiplyIt(AtA_1, Atb)\n",
    "\n",
    "    divide_fac = np.sqrt(np.sum(np.multiply(N, N), axis=2))\n",
    "    # with np.errstate(divide='ignore'):\n",
    "    b = np.divide(-detAtA, divide_fac)\n",
    "    for i in range(3):\n",
    "        N[:, :, i] = np.divide(N[:, :, i], divide_fac)\n",
    "\n",
    "    # Reorient the normals to point out from the scene.\n",
    "    # with np.errstate(invalid='ignore'):\n",
    "    SN = np.sign(N[:, :, 2])\n",
    "    SN[SN == 0] = 1\n",
    "    extend_SN = np.expand_dims(SN, axis=2)\n",
    "    extend_SN = np.concatenate((extend_SN, extend_SN, extend_SN), axis=2)\n",
    "    N = np.multiply(N, extend_SN)\n",
    "    b = np.multiply(b, SN)\n",
    "    sn = np.sign(np.sum(np.multiply(N, XYZf), axis=2))\n",
    "    sn[np.isnan(sn)] = 1\n",
    "    sn[sn == 0] = 1\n",
    "    extend_sn = np.expand_dims(sn, axis=2)\n",
    "    N = np.multiply(extend_sn, N)\n",
    "    b = np.multiply(b, sn)\n",
    "    return N, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "getCameraParam: get the camera matrix\n",
    "colOrZ: color or depth\n",
    "'''\n",
    "def getCameraParam(colorOrZ='color'):\n",
    "    if colorOrZ == 'color':\n",
    "        fx_rgb = 5.1885790117450188e+02\n",
    "        fy_rgb = 5.1946961112127485e+02\n",
    "        cx_rgb = 3.2558244941119034e+02\n",
    "        cy_rgb = 2.5373616633400465e+02\n",
    "        C = np.array([[fx_rgb, 0, cx_rgb], [0, fy_rgb, cy_rgb], [0, 0, 1]])\n",
    "    else:\n",
    "        fx_d = 5.8262448167737955e+02\n",
    "        fy_d = 5.8269103270988637e+02\n",
    "        cx_d = 3.1304475870804731e+02\n",
    "        cy_d = 2.3844389626620386e+02\n",
    "        C = np.array([[fx_d, 0, cx_d], [0, fy_d, cy_d], [0, 0, 1]])\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max gray value:  0.0255\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Conversion to HHA\n",
    "# --*-- coding:utf-8 --*--\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "\n",
    "\n",
    "'''\n",
    "must use 'COLOR_BGR2GRAY' here, or you will get a different gray-value with what MATLAB gets.\n",
    "'''\n",
    "def getImage(root='/home/lorin/Documents/TorchSSC/DATA/scene-sense/RGB/'):\n",
    "    D = cv2.imread(os.path.join(root, 'house1.png'), cv2.COLOR_BGR2GRAY)/10000\n",
    "    # RD = cv2.imread(os.path.join(root, '0_raw.png'), cv2.COLOR_BGR2GRAY)/10000\n",
    "    RD = None\n",
    "    return D, RD\n",
    "\n",
    "'''\n",
    "C: Camera matrix\n",
    "D: Depth image, the unit of each element in it is \"meter\"\n",
    "RD: Raw depth image, the unit of each element in it is \"meter\"\n",
    "'''\n",
    "def getHHA(C, D, RD):\n",
    "    missingMask = (RD == 0)\n",
    "    pc, N, yDir, h, pcRot, NRot = processDepthImage(D * 100, missingMask, C)\n",
    "\n",
    "    tmp = np.multiply(N, yDir)\n",
    "    acosValue = np.minimum(1,np.maximum(-1,np.sum(tmp, axis=2)))\n",
    "    angle = np.array([math.degrees(math.acos(x)) for x in acosValue.flatten()])\n",
    "    angle = np.reshape(angle, h.shape)\n",
    "\n",
    "    '''\n",
    "    Must convert nan to 180 as the MATLAB program actually does. \n",
    "    Or we will get a HHA image whose border region is different\n",
    "    with that of MATLAB program's output.\n",
    "    '''\n",
    "    angle[np.isnan(angle)] = 180        \n",
    "\n",
    "\n",
    "    pc[:,:,2] = np.maximum(pc[:,:,2], 100)\n",
    "    I = np.zeros(pc.shape)\n",
    "\n",
    "    # opencv-python save the picture in BGR order.\n",
    "    I[:,:,2] = 31000/pc[:,:,2]\n",
    "    I[:,:,1] = h\n",
    "    I[:,:,0] = (angle + 128-90)\n",
    "\n",
    "    # print(np.isnan(angle))\n",
    "\n",
    "    '''\n",
    "    np.uint8 seems to use 'floor', but in matlab, it seems to use 'round'.\n",
    "    So I convert it to integer myself.\n",
    "    '''\n",
    "    I = np.rint(I)\n",
    "\n",
    "    # np.uint8: 256->1, but in MATLAB, uint8: 256->255\n",
    "    I[I>255] = 255\n",
    "    HHA = I.astype(np.uint8)\n",
    "    return HHA\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    D, RD = getImage()\n",
    "    camera_matrix = getCameraParam('color')\n",
    "    print('max gray value: ', np.max(D))        # make sure that the image is in 'meter'\n",
    "    hha = getHHA(camera_matrix, D, RD)\n",
    "    # hha_complete = getHHA(camera_matrix, D, D)\n",
    "    # cv2.imwrite('demo/hha.png', hha)\n",
    "    # cv2.imwrite('demo/hha_complete.png', hha_complete)\n",
    "    cv2.imshow(\"HHA image\", hha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-ssc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
